{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import (NeighborhoodComponentsAnalysis,KNeighborsClassifier)\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"test.csv\")\n",
    "train=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education\n",
       "Graduate                 531\n",
       "Post Graduate            432\n",
       "12th Pass                349\n",
       "Graduate Professional    339\n",
       "10th Pass                227\n",
       "8th Pass                  78\n",
       "Doctorate                 52\n",
       "Others                    28\n",
       "Literate                  14\n",
       "5th Pass                   9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_mapping = {'Literate': 0, '5th Pass': 1, '8th Pass': 2, '10th Pass': 3, \n",
    "                     '12th Pass': 4, 'Graduate': 5, 'Post Graduate': 6, \n",
    "                     'Graduate Professional': 7, 'Doctorate': 8, 'Others': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>Constituency ∇</th>\n",
       "      <th>Party</th>\n",
       "      <th>Criminal Case</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Liabilities</th>\n",
       "      <th>state</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>M.K. Mohan</td>\n",
       "      <td>ANNA NAGAR</td>\n",
       "      <td>DMK</td>\n",
       "      <td>4</td>\n",
       "      <td>211 Crore+</td>\n",
       "      <td>2 Crore+</td>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>8th Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Khatik Ramesh Prasad</td>\n",
       "      <td>KARERA (SC)</td>\n",
       "      <td>BJP</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Crore+</td>\n",
       "      <td>0</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>12th Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr. Mantar Gowda</td>\n",
       "      <td>MADIKERI</td>\n",
       "      <td>INC</td>\n",
       "      <td>0</td>\n",
       "      <td>7 Crore+</td>\n",
       "      <td>22 Lac+</td>\n",
       "      <td>KARNATAKA</td>\n",
       "      <td>Post Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Kundan Kumar</td>\n",
       "      <td>BEGUSARAI</td>\n",
       "      <td>BJP</td>\n",
       "      <td>0</td>\n",
       "      <td>9 Crore+</td>\n",
       "      <td>24 Lac+</td>\n",
       "      <td>BIHAR</td>\n",
       "      <td>Post Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Swapan Majumder</td>\n",
       "      <td>BANGAON DAKSHIN (SC)</td>\n",
       "      <td>BJP</td>\n",
       "      <td>2</td>\n",
       "      <td>2 Crore+</td>\n",
       "      <td>61 Lac+</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>8th Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID             Candidate        Constituency ∇ Party  Criminal Case  \\\n",
       "0   0            M.K. Mohan            ANNA NAGAR   DMK              4   \n",
       "1   1  Khatik Ramesh Prasad           KARERA (SC)   BJP              0   \n",
       "2   2      Dr. Mantar Gowda              MADIKERI   INC              0   \n",
       "3   3          Kundan Kumar             BEGUSARAI   BJP              0   \n",
       "4   4       Swapan Majumder  BANGAON DAKSHIN (SC)   BJP              2   \n",
       "\n",
       "  Total Assets Liabilities           state      Education  \n",
       "0   211 Crore+    2 Crore+      TAMIL NADU       8th Pass  \n",
       "1     1 Crore+           0  MADHYA PRADESH      12th Pass  \n",
       "2     7 Crore+     22 Lac+       KARNATAKA  Post Graduate  \n",
       "3     9 Crore+     24 Lac+           BIHAR  Post Graduate  \n",
       "4     2 Crore+     61 Lac+     WEST BENGAL       8th Pass  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareData(data):\n",
    "    data=data.drop(columns=['ID','Candidate','Constituency ∇'])\n",
    "    data.iloc[:,[2,3]]=(data.iloc[:,[2,3]]).apply(lambda x: x.str.replace(' Crore+','00000'))\n",
    "    data.iloc[:,[2,3]]=(data.iloc[:,[2,3]]).apply(lambda x: x.str.replace(' Lac+','000'))\n",
    "    data.iloc[:,[2,3]]=(data.iloc[:,[2,3]]).apply(lambda x: x.str.replace(' Thou+','0'))\n",
    "    data.iloc[:,[2,3]]=(data.iloc[:,[2,3]]).apply(lambda x: x.str.replace(' Hund+',''))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train and y_train are your training features and labels\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "accuracy_scorer=make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transform(data,eduEncoder,type='train'):\n",
    "    scaler=StandardScaler()\n",
    "    minmax=MinMaxScaler()\n",
    "    encoder=OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    data[['Total Assets', 'Liabilities']] = scaler.fit_transform(data[['Total Assets', 'Liabilities']])\n",
    "    # data=data.drop(columns=['Party'])\n",
    "    # data[['Criminal Case']]=scaler.fit_transform(data[['Criminal Case']])\n",
    "    # data['Party']=encoders[0].transform(data['Party'])\n",
    "    # data['state']=encoders[1].transform(data['state'])\n",
    "# Fit and transform the encoder\n",
    "    encoded_features = encoder.fit_transform(data[['Party', 'state']])\n",
    "\n",
    "    # Get the feature names from the encoder\n",
    "    feature_names = encoder.get_feature_names_out(['Party', 'state'])\n",
    "\n",
    "    # Create a DataFrame from the transformed data with the correct column names\n",
    "    encoded_data = pd.DataFrame(encoded_features, columns=feature_names)\n",
    "\n",
    "    data = pd.concat([data.drop(['Party', 'state'], axis=1), encoded_data], axis=1)\n",
    "    data = data.astype({'Total Assets': float, 'Liabilities':float})\n",
    "    data[\"Criminal Case\"] = (data[\"Criminal Case\"] > 0).astype(int) # binary variable\n",
    "    data[\"Assets_liability\"] =  (data['Total Assets']>data['Liabilities']).astype(int)# asset to liability ratio prop to education\n",
    "    if(type=='test'):\n",
    "        # data=pd.get_dummies(data).astype(int)\n",
    "        # data = data.astype({'Party': int, 'Total Assets': float, 'Liabilities':float,'state':int})\n",
    "        data=data.drop(columns=['Liabilities','Total Assets']) \n",
    "        return data\n",
    "    # data['Education']=encoders[2].transform(data['Education'])\n",
    "    data['Education']=data['Education'].map(eduEncoder)\n",
    "    y=data['Education']\n",
    "    # data = data.astype({'Total Assets': float, 'Liabilities':float,'Education':int})\n",
    "    X=data.drop(columns=['Education','Liabilities','Total Assets']) \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubmission(education_mapping,model,X_test):\n",
    "    y_test=model.predict(X_test)\n",
    "    df = pd.read_csv('test.csv')\n",
    "    df = df[['ID']]\n",
    "    # df['Education']=encoderEducation.classes_[y_test]\n",
    "    # df['Education'] = [list(education_mapping.keys())[9] if i > 8 else list(education_mapping.keys())[i] for i in y_test]\n",
    "    df['Education'] = [list(education_mapping.keys())[i] for i in y_test]\n",
    "\n",
    "    # Save the DataFrame to a new CSV file\n",
    "    df.to_csv('output.csv', index=False)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getF1Score(model,X_val,y_val):\n",
    "    y_pred = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred,average='weighted')\n",
    "    print(\"F1 Score:\", f1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimiseModel(model,X,y,param_grid):\n",
    "\n",
    "    # Initialize GridSearchCV with F1 score as the scoring metric\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=f1_scorer, n_jobs=-1)\n",
    "    # grid_search = RandomizedSearchCV(estimator = model, param_distributions = param_grid, cv = 5, scoring=f1_scorer, n_jobs = -1)\n",
    "    # Perform grid search to find the best parameters\n",
    "    grid_search.fit(X ,y)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best F1 Score:\", best_score)\n",
    "    return best_params\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=PrepareData(test)\n",
    "train_data=PrepareData(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Criminal Case</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Liabilities</th>\n",
       "      <th>state</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DMK</td>\n",
       "      <td>4</td>\n",
       "      <td>21100000</td>\n",
       "      <td>200000</td>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>8th Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BJP</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>12th Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INC</td>\n",
       "      <td>0</td>\n",
       "      <td>700000</td>\n",
       "      <td>22000</td>\n",
       "      <td>KARNATAKA</td>\n",
       "      <td>Post Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BJP</td>\n",
       "      <td>0</td>\n",
       "      <td>900000</td>\n",
       "      <td>24000</td>\n",
       "      <td>BIHAR</td>\n",
       "      <td>Post Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BJP</td>\n",
       "      <td>2</td>\n",
       "      <td>200000</td>\n",
       "      <td>61000</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>8th Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>CPI</td>\n",
       "      <td>1</td>\n",
       "      <td>61000</td>\n",
       "      <td>10000</td>\n",
       "      <td>KERALA</td>\n",
       "      <td>Graduate Professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>INC</td>\n",
       "      <td>0</td>\n",
       "      <td>200000</td>\n",
       "      <td>8000</td>\n",
       "      <td>RAJASTHAN</td>\n",
       "      <td>10th Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>BJP</td>\n",
       "      <td>0</td>\n",
       "      <td>1300000</td>\n",
       "      <td>85000</td>\n",
       "      <td>UTTAR PRADESH</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>NCP</td>\n",
       "      <td>1</td>\n",
       "      <td>2500000</td>\n",
       "      <td>94000</td>\n",
       "      <td>MAHARASHTRA</td>\n",
       "      <td>12th Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>BJP</td>\n",
       "      <td>0</td>\n",
       "      <td>11000</td>\n",
       "      <td>0</td>\n",
       "      <td>ARUNACHAL PRADESH</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2059 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Party  Criminal Case Total Assets Liabilities              state  \\\n",
       "0      DMK              4     21100000      200000         TAMIL NADU   \n",
       "1      BJP              0       100000           0     MADHYA PRADESH   \n",
       "2      INC              0       700000       22000          KARNATAKA   \n",
       "3      BJP              0       900000       24000              BIHAR   \n",
       "4      BJP              2       200000       61000        WEST BENGAL   \n",
       "...    ...            ...          ...         ...                ...   \n",
       "2054   CPI              1        61000       10000             KERALA   \n",
       "2055   INC              0       200000        8000          RAJASTHAN   \n",
       "2056   BJP              0      1300000       85000      UTTAR PRADESH   \n",
       "2057   NCP              1      2500000       94000        MAHARASHTRA   \n",
       "2058   BJP              0        11000           0  ARUNACHAL PRADESH   \n",
       "\n",
       "                  Education  \n",
       "0                  8th Pass  \n",
       "1                 12th Pass  \n",
       "2             Post Graduate  \n",
       "3             Post Graduate  \n",
       "4                  8th Pass  \n",
       "...                     ...  \n",
       "2054  Graduate Professional  \n",
       "2055              10th Pass  \n",
       "2056               Graduate  \n",
       "2057              12th Pass  \n",
       "2058               Graduate  \n",
       "\n",
       "[2059 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=pd.read_csv(\"test.csv\")\n",
    "# train=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train=PrepareData(train)\n",
    "# test=PrepareData(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Party'] = train['Party'].astype('category').cat.codes\n",
    "# train['Education'] = train['Education'].astype('category').cat.codes\n",
    "# train['state'] = train['state'].astype('category').cat.codes\n",
    "\n",
    "# train = train.astype({'Party': int, 'Total Assets': float, 'Liabilities':float,'state':int,'Education':int})\n",
    "# train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from scipy.stats import chi2_contingency\n",
    "\n",
    "# # Assume 'data' is your DataFrame with 'Party' and 'Education level' columns\n",
    "\n",
    "# # Create a contingency table (cross-tabulation)\n",
    "# contingency_table = pd.crosstab(train['Criminal Case'], train['Education'])\n",
    "\n",
    "\n",
    "# # Perform the chi-squared test\n",
    "# chi2_stat, p_val, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Chi-squared statistic:\", chi2_stat)\n",
    "# print(\"p-value:\", p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoderParty=LabelEncoder()\n",
    "encoderState=LabelEncoder()\n",
    "encoderEducation=LabelEncoder()\n",
    "encoderParty.fit(train['Party'])\n",
    "encoderState.fit(train['state'])\n",
    "encoderEducation.fit(train['Education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=Transform(train_data,education_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Criminal Case</th>\n",
       "      <th>Party_AAP</th>\n",
       "      <th>Party_AIADMK</th>\n",
       "      <th>Party_AITC</th>\n",
       "      <th>Party_BJD</th>\n",
       "      <th>Party_BJP</th>\n",
       "      <th>Party_CPI</th>\n",
       "      <th>Party_CPI(M)</th>\n",
       "      <th>Party_DMK</th>\n",
       "      <th>Party_INC</th>\n",
       "      <th>...</th>\n",
       "      <th>state_PUDUCHERRY</th>\n",
       "      <th>state_PUNJAB</th>\n",
       "      <th>state_RAJASTHAN</th>\n",
       "      <th>state_SIKKIM</th>\n",
       "      <th>state_TAMIL NADU</th>\n",
       "      <th>state_TRIPURA</th>\n",
       "      <th>state_UTTAR PRADESH</th>\n",
       "      <th>state_UTTARAKHAND</th>\n",
       "      <th>state_WEST BENGAL</th>\n",
       "      <th>Assets_liability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2059 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Criminal Case  Party_AAP  Party_AIADMK  Party_AITC  Party_BJD  \\\n",
       "0                 1        0.0           0.0         0.0        0.0   \n",
       "1                 0        0.0           0.0         0.0        0.0   \n",
       "2                 0        0.0           0.0         0.0        0.0   \n",
       "3                 0        0.0           0.0         0.0        0.0   \n",
       "4                 1        0.0           0.0         0.0        0.0   \n",
       "...             ...        ...           ...         ...        ...   \n",
       "2054              1        0.0           0.0         0.0        0.0   \n",
       "2055              0        0.0           0.0         0.0        0.0   \n",
       "2056              0        0.0           0.0         0.0        0.0   \n",
       "2057              1        0.0           0.0         0.0        0.0   \n",
       "2058              0        0.0           0.0         0.0        0.0   \n",
       "\n",
       "      Party_BJP  Party_CPI  Party_CPI(M)  Party_DMK  Party_INC  ...  \\\n",
       "0           0.0        0.0           0.0        1.0        0.0  ...   \n",
       "1           1.0        0.0           0.0        0.0        0.0  ...   \n",
       "2           0.0        0.0           0.0        0.0        1.0  ...   \n",
       "3           1.0        0.0           0.0        0.0        0.0  ...   \n",
       "4           1.0        0.0           0.0        0.0        0.0  ...   \n",
       "...         ...        ...           ...        ...        ...  ...   \n",
       "2054        0.0        1.0           0.0        0.0        0.0  ...   \n",
       "2055        0.0        0.0           0.0        0.0        1.0  ...   \n",
       "2056        1.0        0.0           0.0        0.0        0.0  ...   \n",
       "2057        0.0        0.0           0.0        0.0        0.0  ...   \n",
       "2058        1.0        0.0           0.0        0.0        0.0  ...   \n",
       "\n",
       "      state_PUDUCHERRY  state_PUNJAB  state_RAJASTHAN  state_SIKKIM  \\\n",
       "0                  0.0           0.0              0.0           0.0   \n",
       "1                  0.0           0.0              0.0           0.0   \n",
       "2                  0.0           0.0              0.0           0.0   \n",
       "3                  0.0           0.0              0.0           0.0   \n",
       "4                  0.0           0.0              0.0           0.0   \n",
       "...                ...           ...              ...           ...   \n",
       "2054               0.0           0.0              0.0           0.0   \n",
       "2055               0.0           0.0              1.0           0.0   \n",
       "2056               0.0           0.0              0.0           0.0   \n",
       "2057               0.0           0.0              0.0           0.0   \n",
       "2058               0.0           0.0              0.0           0.0   \n",
       "\n",
       "      state_TAMIL NADU  state_TRIPURA  state_UTTAR PRADESH  state_UTTARAKHAND  \\\n",
       "0                  1.0            0.0                  0.0                0.0   \n",
       "1                  0.0            0.0                  0.0                0.0   \n",
       "2                  0.0            0.0                  0.0                0.0   \n",
       "3                  0.0            0.0                  0.0                0.0   \n",
       "4                  0.0            0.0                  0.0                0.0   \n",
       "...                ...            ...                  ...                ...   \n",
       "2054               0.0            0.0                  0.0                0.0   \n",
       "2055               0.0            0.0                  0.0                0.0   \n",
       "2056               0.0            0.0                  1.0                0.0   \n",
       "2057               0.0            0.0                  0.0                0.0   \n",
       "2058               0.0            0.0                  0.0                0.0   \n",
       "\n",
       "      state_WEST BENGAL  Assets_liability  \n",
       "0                   0.0                 1  \n",
       "1                   0.0                 0  \n",
       "2                   0.0                 1  \n",
       "3                   0.0                 1  \n",
       "4                   1.0                 0  \n",
       "...                 ...               ...  \n",
       "2054                0.0                 0  \n",
       "2055                0.0                 0  \n",
       "2056                0.0                 1  \n",
       "2057                0.0                 1  \n",
       "2058                0.0                 0  \n",
       "\n",
       "[2059 rows x 53 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Criminal Case</th>\n",
       "      <th>Party_AAP</th>\n",
       "      <th>Party_AIADMK</th>\n",
       "      <th>Party_AITC</th>\n",
       "      <th>Party_BJD</th>\n",
       "      <th>Party_BJP</th>\n",
       "      <th>Party_CPI</th>\n",
       "      <th>Party_CPI(M)</th>\n",
       "      <th>Party_DMK</th>\n",
       "      <th>Party_INC</th>\n",
       "      <th>...</th>\n",
       "      <th>state_PUDUCHERRY</th>\n",
       "      <th>state_PUNJAB</th>\n",
       "      <th>state_RAJASTHAN</th>\n",
       "      <th>state_SIKKIM</th>\n",
       "      <th>state_TAMIL NADU</th>\n",
       "      <th>state_TRIPURA</th>\n",
       "      <th>state_UTTAR PRADESH</th>\n",
       "      <th>state_UTTARAKHAND</th>\n",
       "      <th>state_WEST BENGAL</th>\n",
       "      <th>Assets_liability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2059 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Criminal Case  Party_AAP  Party_AIADMK  Party_AITC  Party_BJD  \\\n",
       "0                 1        0.0           0.0         0.0        0.0   \n",
       "1                 0        0.0           0.0         0.0        0.0   \n",
       "2                 0        0.0           0.0         0.0        0.0   \n",
       "3                 0        0.0           0.0         0.0        0.0   \n",
       "4                 1        0.0           0.0         0.0        0.0   \n",
       "...             ...        ...           ...         ...        ...   \n",
       "2054              1        0.0           0.0         0.0        0.0   \n",
       "2055              0        0.0           0.0         0.0        0.0   \n",
       "2056              0        0.0           0.0         0.0        0.0   \n",
       "2057              1        0.0           0.0         0.0        0.0   \n",
       "2058              0        0.0           0.0         0.0        0.0   \n",
       "\n",
       "      Party_BJP  Party_CPI  Party_CPI(M)  Party_DMK  Party_INC  ...  \\\n",
       "0           0.0        0.0           0.0        1.0        0.0  ...   \n",
       "1           1.0        0.0           0.0        0.0        0.0  ...   \n",
       "2           0.0        0.0           0.0        0.0        1.0  ...   \n",
       "3           1.0        0.0           0.0        0.0        0.0  ...   \n",
       "4           1.0        0.0           0.0        0.0        0.0  ...   \n",
       "...         ...        ...           ...        ...        ...  ...   \n",
       "2054        0.0        1.0           0.0        0.0        0.0  ...   \n",
       "2055        0.0        0.0           0.0        0.0        1.0  ...   \n",
       "2056        1.0        0.0           0.0        0.0        0.0  ...   \n",
       "2057        0.0        0.0           0.0        0.0        0.0  ...   \n",
       "2058        1.0        0.0           0.0        0.0        0.0  ...   \n",
       "\n",
       "      state_PUDUCHERRY  state_PUNJAB  state_RAJASTHAN  state_SIKKIM  \\\n",
       "0                  0.0           0.0              0.0           0.0   \n",
       "1                  0.0           0.0              0.0           0.0   \n",
       "2                  0.0           0.0              0.0           0.0   \n",
       "3                  0.0           0.0              0.0           0.0   \n",
       "4                  0.0           0.0              0.0           0.0   \n",
       "...                ...           ...              ...           ...   \n",
       "2054               0.0           0.0              0.0           0.0   \n",
       "2055               0.0           0.0              1.0           0.0   \n",
       "2056               0.0           0.0              0.0           0.0   \n",
       "2057               0.0           0.0              0.0           0.0   \n",
       "2058               0.0           0.0              0.0           0.0   \n",
       "\n",
       "      state_TAMIL NADU  state_TRIPURA  state_UTTAR PRADESH  state_UTTARAKHAND  \\\n",
       "0                  1.0            0.0                  0.0                0.0   \n",
       "1                  0.0            0.0                  0.0                0.0   \n",
       "2                  0.0            0.0                  0.0                0.0   \n",
       "3                  0.0            0.0                  0.0                0.0   \n",
       "4                  0.0            0.0                  0.0                0.0   \n",
       "...                ...            ...                  ...                ...   \n",
       "2054               0.0            0.0                  0.0                0.0   \n",
       "2055               0.0            0.0                  0.0                0.0   \n",
       "2056               0.0            0.0                  1.0                0.0   \n",
       "2057               0.0            0.0                  0.0                0.0   \n",
       "2058               0.0            0.0                  0.0                0.0   \n",
       "\n",
       "      state_WEST BENGAL  Assets_liability  \n",
       "0                   0.0                 1  \n",
       "1                   0.0                 0  \n",
       "2                   0.0                 1  \n",
       "3                   0.0                 1  \n",
       "4                   1.0                 0  \n",
       "...                 ...               ...  \n",
       "2054                0.0                 0  \n",
       "2055                0.0                 0  \n",
       "2056                0.0                 1  \n",
       "2057                0.0                 1  \n",
       "2058                0.0                 0  \n",
       "\n",
       "[2059 rows x 53 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def oversample(X,y,sampling_strategy):\n",
    "    # sampling_strategy = {\n",
    "    #     5: 531,   # Keep the majority class unchanged\n",
    "    #     6: 450, # 432/531\n",
    "    #     4: 450, # 349/531\n",
    "    #     7: 450, # 339/531\n",
    "    #     3: 300, # 227/531\n",
    "    #     2: 100, # 78/531\n",
    "    #     8: 100, # 52/531\n",
    "    #     9: 100, # 28/531\n",
    "    #     0: 100, # 14/531\n",
    "    #     1: 100, # 9/531\n",
    "    # }\n",
    "\n",
    "    smote = SMOTE(random_state=69,sampling_strategy=sampling_strategy)\n",
    "\n",
    "    # Apply SMOTE to generate synthetic samples\n",
    "    X_resampled, y_resampled = smote.fit_resample(X,y)\n",
    "\n",
    "    return X_resampled,y_resampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=Transform(test_data,np.array((encoderParty,encoderState,encoderEducation)),'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.15,random_state=69,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education\n",
       "5    451\n",
       "6    367\n",
       "4    297\n",
       "7    288\n",
       "3    193\n",
       "2     66\n",
       "8     44\n",
       "9     24\n",
       "0     12\n",
       "1      8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling_strategy = {\n",
    "#     5: 451,   # Keep the majority class unchanged\n",
    "#     6: 367, # 432/531\n",
    "#     4: 297, # 349/531\n",
    "#     7: 288, # 339/531\n",
    "#     3: 250, # 227/531\n",
    "#     2: 150, # 78/531\n",
    "#     8: 125, # 52/531\n",
    "#     9: 70, # 28/531\n",
    "#     0: 50, # 14/531\n",
    "#     1: 50, # 9/531\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_strategy= {\n",
    "    5: 451,   # Keep the majority class unchanged\n",
    "    6: 367, # 432/531\n",
    "    4: 297, # 349/531\n",
    "    7: 288, # 339/531\n",
    "    3: 250, # 227/531\n",
    "    2: 150, # 78/531\n",
    "    8: 125, # 52/531\n",
    "    9: 75, # 28/531\n",
    "    0: 50, # 14/531\n",
    "    1: 50, # 9/531\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled,y_resampled=oversample(X_train,y_train,sampling_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the classifier on the testing data\n",
    "# accuracy = classifier.score(X_val, y_val)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heirarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heirarchialModel(heirarchy,X,y):\n",
    "\n",
    "    broad_trained_models = {}\n",
    "    y1=y.copy()\n",
    "\n",
    "    # Dictionary to store trained models for predicting finer classes within each broad class\n",
    "    finer_trained_models = {}\n",
    "    # Train classification models for broad classes\n",
    "    for broad_level, broad_classes in heirarchy.items():\n",
    "        broad_subset_indices = y.isin(broad_classes)\n",
    "        y1[broad_subset_indices]=broad_level\n",
    "        # print(broad_classes,broad_subset_indices)\n",
    "        X_train_broad = X[broad_subset_indices]\n",
    "        y_train_broad = y[broad_subset_indices]\n",
    "        # X_train, X_test, y_train, y_test = train_test_split(broad_subset_X, broad_subset_y, test_size=0.2, random_state=69, stratify=broad_subset_y)\n",
    "        # clf = RandomForestClassifier(random_state=69)\n",
    "        clf=optimiseRandomForest(X_train_broad,y_train_broad)\n",
    "        clf.fit(X_train_broad, y_train_broad)\n",
    "        broad_trained_models[broad_level] = clf\n",
    "\n",
    "    BroadModel = optimiseGboost(X,y1)\n",
    "    BroadModel.fit(X, y1)\n",
    "    return BroadModel,broad_trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_classification(X_val,y_val,BroadModel,broad_trained_models):\n",
    "    y_predict1=BroadModel.predict(X_val)\n",
    "    y_predict=np.zeros((len(y_predict1)))\n",
    "    for i in range(0,len(y_predict1)):\n",
    "        y_predict[i]=broad_trained_models[y_predict1[i]].predict(X_val.iloc[[i]])[0]\n",
    "    f1 = f1_score(y_val, y_predict,average='weighted')\n",
    "    print(y_predict)\n",
    "    print(\"F1 Score:\", f1)  \n",
    "    return y_predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_leaf_nodes': 200, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best F1 Score: 0.6341748879358635\n",
      "Best Parameters: {'max_leaf_nodes': 200, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best F1 Score: 1.0\n",
      "Best Parameters: {'max_leaf_nodes': 200, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best F1 Score: 0.3904616823342922\n",
      "Best Parameters: {'max_leaf_nodes': 200, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best F1 Score: 0.5686147186147187\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_leaf_nodes': 200, 'n_estimators': 200}\n",
      "Best F1 Score: 0.5307902964190554\n",
      "F1 Score: 0.21980086607772314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5., 5., 4., 5., 5., 5., 5., 7., 5., 7., 7., 6., 5., 7., 7., 5., 6.,\n",
       "       6., 6., 5., 8., 5., 7., 5., 5., 8., 5., 5., 7., 6., 7., 5., 6., 6.,\n",
       "       6., 5., 5., 6., 6., 5., 6., 5., 5., 5., 5., 6., 5., 5., 5., 5., 5.,\n",
       "       7., 6., 6., 6., 6., 2., 5., 0., 5., 5., 6., 5., 5., 6., 6., 7., 5.,\n",
       "       5., 5., 6., 6., 5., 5., 7., 5., 6., 7., 6., 7., 4., 5., 7., 6., 6.,\n",
       "       6., 5., 6., 4., 6., 6., 5., 7., 7., 7., 5., 7., 6., 5., 5., 7., 5.,\n",
       "       7., 5., 5., 6., 7., 7., 5., 7., 5., 6., 7., 5., 6., 4., 6., 5., 5.,\n",
       "       5., 7., 7., 5., 5., 5., 5., 5., 6., 6., 8., 6., 7., 5., 5., 6., 6.,\n",
       "       5., 5., 6., 4., 5., 6., 5., 5., 6., 5., 6., 6., 6., 6., 5., 3., 6.,\n",
       "       5., 6., 7., 6., 3., 6., 5., 5., 6., 7., 5., 5., 2., 5., 6., 5., 9.,\n",
       "       4., 7., 5., 6., 7., 5., 6., 6., 6., 7., 5., 7., 6., 6., 5., 5., 6.,\n",
       "       5., 6., 6., 3., 6., 6., 7., 7., 3., 5., 5., 6., 5., 2., 6., 7., 7.,\n",
       "       7., 6., 4., 7., 6., 6., 5., 5., 5., 5., 6., 4., 7., 7., 3., 6., 5.,\n",
       "       5., 6., 6., 6., 5., 5., 7., 7., 5., 5., 6., 6., 7., 6., 5., 6., 5.,\n",
       "       7., 5., 6., 5., 5., 6., 6., 5., 5., 6., 5., 5., 5., 5., 7., 5., 5.,\n",
       "       7., 5., 6., 5., 6., 5., 5., 6., 5., 6., 7., 7., 4., 7., 5., 5., 5.,\n",
       "       6., 5., 5., 7., 5., 5., 5., 5., 3., 7., 6., 7., 3., 6., 5., 5., 3.,\n",
       "       5., 6., 5., 7., 7., 5., 6., 3., 5., 5., 7., 6., 8., 5., 7., 6., 6.,\n",
       "       5., 5., 5.])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heirarchy = {\n",
    "    0: [1, 2, 3],\n",
    "    1: [4],\n",
    "    2: [5, 6, 7, 8],\n",
    "    3: [0, 9]\n",
    "}\n",
    "BroadModel,broad_trained_models=heirarchialModel(heirarchy,X_train,y_train)\n",
    "hierarchical_classification(X_val,y_val,BroadModel,broad_trained_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 7. 4. ... 5. 8. 5.]\n",
      "F1 Score: 0.004357298474945534\n"
     ]
    }
   ],
   "source": [
    "y_t=np.ones(len(X_test))\n",
    "y_test=hierarchical_classification(X_test,y_t,BroadModel,broad_trained_models)\n",
    "y_test=y_test.astype(int)\n",
    "df = pd.read_csv('test.csv')\n",
    "df = df[['ID']]\n",
    "df['Education'] = [list(education_mapping.keys())[i] for i in y_test]\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Cross-Validation Scores, A: 0.21117148875251415  B:  0.24014656713212693\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dt_classifier=DecisionTreeClassifier(random_state=1)\n",
    "dt_scoresA = cross_val_score(dt_classifier, X_train, y_train, cv=5,scoring=f1_scorer)\n",
    "dt_scoresF = cross_val_score(dt_classifier, X_resampled, y_resampled, cv=5,scoring=f1_scorer)\n",
    "print(\"Decision Tree Classifier Cross-Validation Scores, A:\", dt_scoresA.mean(),\" B: \",dt_scoresF.mean() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimiseDecisionTree(X,y):\n",
    "    # Define the parameter grid to search\n",
    "    param_grid = {\n",
    "        # 'criterion': ['gini', 'entropy'],\n",
    "        # 'max_depth': [1, 2, 5, 10, 15],\n",
    "        'min_samples_split': [2, 3, 5, 10],\n",
    "        'min_samples_leaf': [1, 2,5, 10, 15],\n",
    "        # 'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_leaf_nodes':[200, 500,700,1000,1500,2000]\n",
    "    }\n",
    "    dt_classifier=DecisionTreeClassifier(random_state=1)\n",
    "    best_params=optimiseModel(dt_classifier,X,y,param_grid)\n",
    "    # Initialize GridSearchCV with F1 score as the scoring metric\n",
    "    best_dt_classifier = DecisionTreeClassifier(random_state=1,**best_params)\n",
    "    return best_dt_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_leaf_nodes': 700, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best F1 Score: 0.2535454168806068\n",
      "F1 Score: 0.19831961914027646\n"
     ]
    }
   ],
   "source": [
    "best_dt_classifier=optimiseDecisionTree(X_resampled,y_resampled)\n",
    "best_dt_classifier.fit(X_resampled, y_resampled)\n",
    "getF1Score(best_dt_classifier,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=createSubmission(education_mapping,best_dt_classifier,X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dt_classifier.fit(X, y)\n",
    "full=createSubmission(education_mapping,best_dt_classifier,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Cross-Validation Scores, A: 0.19813724271775218  B:  0.2642110347666645\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=69,oob_score=True)\n",
    "rf_scoresA = cross_val_score(rf_classifier, X_train, y_train, cv=5,scoring=f1_scorer)\n",
    "rf_scoresF = cross_val_score(rf_classifier, X_resampled, y_resampled, cv=5, scoring=f1_scorer)\n",
    "print(\"Random Forest Classifier Cross-Validation Scores, A:\", rf_scoresA.mean(),\" B: \" ,rf_scoresF.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimiseRandomForest(X,y) :\n",
    "  # Define the parameter grid to search\n",
    "  # param_grid = {\n",
    "  #     'n_estimators': [100,500,1000],\n",
    "  #     # 'criterion': ['gini', 'entropy'],\n",
    "  #     # 'max_depth': [None, 10, 20],\n",
    "  #     'min_samples_split': [5,7,9,11],\n",
    "  #     # 'min_samples_leaf': [1, 2, 5,7,9],\n",
    "  #     'max_leaf_nodes':[200,500,1000,2000]\n",
    "  # }\n",
    "\n",
    "  #     # 'max_features': ['auto', 'sqrt', 'log2']\n",
    "  # # }\n",
    "  param_grid = {\n",
    "  'n_estimators': [50, 100, 150,200],\n",
    "#   Consider both Gini impurity and entropy for split criterion\n",
    "  # 'max_depth': [2, 5, 10, 20, 100],  # Allow the tree to grow deeper or limit its depth\n",
    "  'min_samples_split': [2,5,7,9],  # Vary the minimum number of samples required to split an internal node\n",
    "  'max_leaf_nodes':[200,500,700,1000]\n",
    "  # 'min_samples_leaf': [1, 2, 5], \n",
    "  # 'min_impurity_decrease' : [0.001, 0.005, 0.0001] # Vary the minimum number of samples required to be a leaf node\n",
    "  # 'max_features': ['auto', 'sqrt', 'log2'],  # Consider different ways of selecting features for splitting\n",
    "  # 'max_leaf_nodes': [10, 100, 200, 500]  # Limit the maximum number of leaf nodes\n",
    "  }\n",
    "  # param_grid = {'n_estimators':[100,500,1000,1500],\n",
    "  #               'max_leaf_nodes':[200,500,1000],\n",
    "  #               'min_samples_split':[2,5,7,10,11]\n",
    "  #             #   'max_depth': [None,2,5,10]\n",
    "  #               }\n",
    "  rf_classifier=RandomForestClassifier(random_state=69)\n",
    "  best_params=optimiseModel(rf_classifier,X,y,param_grid)\n",
    "  best_rf_classifier = RandomForestClassifier(random_state=69,**best_params)\n",
    "  return best_rf_classifier\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_leaf_nodes': 200, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best F1 Score: 0.28235528237771435\n",
      "F1 Score: 0.23230705742940352\n"
     ]
    }
   ],
   "source": [
    "best_rf_classifier = optimiseRandomForest(X_resampled,y_resampled)\n",
    "best_rf_classifier.fit(X_resampled, y_resampled)\n",
    "getF1Score(best_rf_classifier,X_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5844660736615426\n"
     ]
    }
   ],
   "source": [
    "getF1Score(best_rf_classifier,X_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 5, ..., 5, 5, 6])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_classifier.fit(X, y)\n",
    "createSubmission(education_mapping,best_rf_classifier,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.18562478265451318\n"
     ]
    }
   ],
   "source": [
    "getF1Score(best_rf_classifier,X_val,y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Cross-Validation Scores, A: 0.20275621636921418  B:  0.18389284739598938\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Logistic Regression\n",
    "logistic_classifier = LogisticRegression(max_iter=10000)\n",
    "logistic_scoresA = cross_val_score(logistic_classifier, X_train, y_train, cv=5,scoring=f1_scorer)\n",
    "logistic_scoresF = cross_val_score(logistic_classifier, X_resampled, y_resampled, cv=5,scoring=f1_scorer)\n",
    "print(\"Logistic Regression Cross-Validation Scores, A:\", logistic_scoresA.mean(),\" B: \",logistic_scoresF.mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 5, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best F1 Score: 0.2051587348632707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.19845515        nan 0.20136258 0.20515873 0.1992092         nan\n",
      " 0.20131749 0.20420947 0.20277436        nan 0.20277225 0.20420331\n",
      " 0.20250313        nan 0.20289985 0.20422229 0.20250313        nan\n",
      " 0.20250313 0.20382719 0.20248745        nan 0.20250313 0.20419359]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'penalty': ['l1', \"l2\"],  # Regularization penalty\n",
    "    'C': [5, 10, 100, 500, 600, 1000], # Inverse of regularization strength,\n",
    "    \"solver\" : [\"liblinear\", \"lbfgs\"]\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV with F1 score as the scoring metric\n",
    "grid_search = GridSearchCV(estimator=logistic_classifier, param_grid=param_grid, cv=5, scoring=f1_scorer, n_jobs=-1)\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best F1 Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.19813331177489987\n"
     ]
    }
   ],
   "source": [
    "# grid_search.fit(X_resampled, y_resampled)\n",
    "getF1Score(grid_search,X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Cross-Validation Scores, A: 0.23016400859631264  B:  0.19895867643669268\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_scoresA = cross_val_score(svm_classifier, X_resampled, y_resampled, cv=5,scoring=accuracy_scorer)\n",
    "svm_scoresF = cross_val_score(svm_classifier, X_train, y_train, cv=5,scoring=f1_scorer)\n",
    "print(\"Support Vector Machine Cross-Validation Scores, A:\", svm_scoresA.mean(),\" B: \",svm_scoresF.mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimiseSVM(X,y):\n",
    "        \n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],  \n",
    "        'gamma': [1, 0.1, 0.01, 0.001], \n",
    "        'kernel': ['rbf', 'linear', 'poly']\n",
    "    }\n",
    "\n",
    "    # Initialize K-Nearest Neighbors Classifier\n",
    "    svm_classifier = SVC(random_state=42)\n",
    "    \n",
    "    # Initialize GridSearchCV with F1 score as the scoring metric\n",
    "    best_params=optimiseModel(svm_classifier,X,y,param_grid)\n",
    "    best_knn_classifier = SVC(random_state=42,**best_params)\n",
    "\n",
    "    return best_knn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.2544695560370561\n",
      "F1 Score: 0.2192395834962284\n"
     ]
    }
   ],
   "source": [
    "best_svm_classifier = optimiseSVM(X_resampled,y_resampled)\n",
    "\n",
    "best_svm_classifier.fit(X_train, y_train)\n",
    "getF1Score(best_svm_classifier,X_val,y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K nearest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "def optimiseKNN(X,y):\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3,4, 5,6, 9,11,15],  # Number of neighbors\n",
    "        'weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
    "    }\n",
    "\n",
    "    # Initialize K-Nearest Neighbors Classifier\n",
    "    knn_classifier = KNeighborsClassifier()\n",
    "    \n",
    "    # Initialize GridSearchCV with F1 score as the scoring metric\n",
    "    best_params=optimiseModel(knn_classifier,X,y,param_grid)\n",
    "    best_knn_classifier = KNeighborsClassifier(**best_params)\n",
    "\n",
    "    return best_knn_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best F1 Score: 0.2491321779105605\n",
      "F1 Score: 0.21067885474632797\n"
     ]
    }
   ],
   "source": [
    "best_knn_classifier = optimiseKNN(X_resampled,y_resampled)\n",
    "\n",
    "best_knn_classifier.fit(X_resampled, y_resampled)\n",
    "getF1Score(best_knn_classifier,X_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 4, ..., 5, 3, 5])"
      ]
     },
     "execution_count": 898,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn_classifier.fit(X_resampled, y_resampled)\n",
    "createSubmission(education_mapping,best_knn_classifier,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16828478964401294\n"
     ]
    }
   ],
   "source": [
    "nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "nca_pipe.fit(X_resampled, y_resampled)\n",
    "print(nca_pipe.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'knn__n_neighbors': 5, 'knn__p': 2, 'knn__weights': 'distance', 'nca__n_components': 3}\n",
      "Best F1 Score: 0.22587835015826863\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'nca__n_components': [1,2,3],  # Number of components for NCA\n",
    "    'knn__n_neighbors': [5,7,9,11],  # Number of neighbors for \n",
    "    'knn__p':[1,2],\n",
    "    'knn__weights': ['uniform', 'distance'],  # Weight function used in prediction for KNN\n",
    "}\n",
    "\n",
    "# Create pipeline\n",
    "nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "knn = KNeighborsClassifier()\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "\n",
    "# Initialize GridSearchCV with F1 score as the scoring metric\n",
    "grid_search = GridSearchCV(estimator=nca_pipe, param_grid=param_grid, cv=5, scoring=f1_scorer, n_jobs=-1)\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best F1 Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.21284737526579203\n"
     ]
    }
   ],
   "source": [
    "# Define parameters for NCA\n",
    "nca_params = {'n_components': 3, 'random_state': 42}\n",
    "\n",
    "# Define parameters for KNN\n",
    "knn_params = {'n_neighbors': 5, 'weights': 'distance','p':2}\n",
    "\n",
    "# Create the pipeline with parameters\n",
    "nca_pipe = Pipeline([\n",
    "    ('nca', NeighborhoodComponentsAnalysis(**nca_params)),\n",
    "    ('knn', KNeighborsClassifier(**knn_params))\n",
    "])\n",
    "best_knn_classifier = nca_pipe\n",
    "best_knn_classifier.fit(X_resampled, y_resampled)\n",
    "getF1Score(best_knn_classifier,X_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 3, ..., 5, 3, 6])"
      ]
     },
     "execution_count": 902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn_classifier.fit(X_resampled, y_resampled)\n",
    "createSubmission(education_mapping,best_knn_classifier,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Cross-Validation Scores, A: 0.19882844129312943  B:  0.24478875758451446\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=69)\n",
    "gb_scoresA = cross_val_score(gb_classifier, X_train, y_train, cv=5,scoring=f1_scorer)\n",
    "gb_scoresF = cross_val_score(gb_classifier, X_resampled, y_resampled, cv=5,scoring=f1_scorer)\n",
    "print(\"Gradient Boosting Classifier Cross-Validation Scores, A:\", gb_scoresA.mean(),\" B: \",gb_scoresF.mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimiseGboost(X,y):\n",
    "# Define the parameter grid to search\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 150,200],\n",
    "        'learning_rate': [0.05, 0.01, 0.1, 0.2, 0.3],\n",
    "        # 'max_depth': [1, 3, 5, 10, 20],\n",
    "        # 'min_samples_split': [1, 5, 10],\n",
    "        # 'min_samples_leaf': [2, 5, 10, 50],\n",
    "        'max_leaf_nodes':[200,500,1000],\n",
    "    }\n",
    "   # Initialize K-Nearest Neighbors Classifier\n",
    "    gb_classifier = GradientBoostingClassifier(random_state=69)\n",
    "    \n",
    "    # Initialize GridSearchCV with F1 score as the scoring metric\n",
    "    best_params=optimiseModel(gb_classifier,X,y,param_grid)\n",
    "    best_gb_classifier = GradientBoostingClassifier(random_state=69,**best_params)\n",
    "\n",
    "    return best_gb_classifier\n",
    "\n",
    "# Initialize GridSearchCV with F1 score as the scoring metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.2, 'max_leaf_nodes': 200, 'n_estimators': 100}\n",
      "Best F1 Score: 0.21468203688696635\n",
      "F1 Score: 0.22363661916400157\n"
     ]
    }
   ],
   "source": [
    "best_gb_classifier = optimiseGboost(X_train,y_train)\n",
    "best_gb_classifier.fit(X_train, y_train)\n",
    "getF1Score(best_gb_classifier,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 3, ..., 5, 8, 6])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gb_classifier.fit(X, y)\n",
    "createSubmission(education_mapping,best_gb_classifier,X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
