{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import (NeighborhoodComponentsAnalysis,KNeighborsClassifier)\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"test.csv\")\n",
    "train=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=(train[train['Total Assets']!='0'])\n",
    "test=(test[test['Total Assets']!='0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10th Pass', '12th Pass', '5th Pass', '8th Pass', 'Doctorate',\n",
       "       'Graduate', 'Graduate Professional', 'Literate', 'Others',\n",
       "       'Post Graduate'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=LabelEncoder()\n",
    "a.fit_transform(train['Education'])\n",
    "a.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ANNA NAGAR', 'KARERA (SC)', 'MADIKERI', ..., 'MODI NAGAR',\n",
       "       'SHIRALA', 'TALIHA'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Constituency ∇\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education\n",
       "Graduate                 484\n",
       "Post Graduate            396\n",
       "12th Pass                311\n",
       "Graduate Professional    306\n",
       "10th Pass                207\n",
       "8th Pass                  75\n",
       "Doctorate                 48\n",
       "Others                    23\n",
       "Literate                  12\n",
       "5th Pass                   8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_mapping = {'Literate': 0, '5th Pass': 1, '8th Pass': 2, '10th Pass': 3, \n",
    "                     '12th Pass': 4, 'Graduate': 5, 'Post Graduate': 6, \n",
    "                     'Graduate Professional': 7, 'Doctorate': 8, 'Others': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>Constituency ∇</th>\n",
       "      <th>Party</th>\n",
       "      <th>Criminal Case</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Liabilities</th>\n",
       "      <th>state</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>M.K. Mohan</td>\n",
       "      <td>ANNA NAGAR</td>\n",
       "      <td>DMK</td>\n",
       "      <td>4</td>\n",
       "      <td>211 Crore+</td>\n",
       "      <td>2 Crore+</td>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>8th Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Khatik Ramesh Prasad</td>\n",
       "      <td>KARERA (SC)</td>\n",
       "      <td>BJP</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Crore+</td>\n",
       "      <td>0</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>12th Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr. Mantar Gowda</td>\n",
       "      <td>MADIKERI</td>\n",
       "      <td>INC</td>\n",
       "      <td>0</td>\n",
       "      <td>7 Crore+</td>\n",
       "      <td>22 Lac+</td>\n",
       "      <td>KARNATAKA</td>\n",
       "      <td>Post Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Kundan Kumar</td>\n",
       "      <td>BEGUSARAI</td>\n",
       "      <td>BJP</td>\n",
       "      <td>0</td>\n",
       "      <td>9 Crore+</td>\n",
       "      <td>24 Lac+</td>\n",
       "      <td>BIHAR</td>\n",
       "      <td>Post Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Swapan Majumder</td>\n",
       "      <td>BANGAON DAKSHIN (SC)</td>\n",
       "      <td>BJP</td>\n",
       "      <td>2</td>\n",
       "      <td>2 Crore+</td>\n",
       "      <td>61 Lac+</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>8th Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID             Candidate        Constituency ∇ Party  Criminal Case  \\\n",
       "0   0            M.K. Mohan            ANNA NAGAR   DMK              4   \n",
       "1   1  Khatik Ramesh Prasad           KARERA (SC)   BJP              0   \n",
       "2   2      Dr. Mantar Gowda              MADIKERI   INC              0   \n",
       "3   3          Kundan Kumar             BEGUSARAI   BJP              0   \n",
       "4   4       Swapan Majumder  BANGAON DAKSHIN (SC)   BJP              2   \n",
       "\n",
       "  Total Assets Liabilities           state      Education  \n",
       "0   211 Crore+    2 Crore+      TAMIL NADU       8th Pass  \n",
       "1     1 Crore+           0  MADHYA PRADESH      12th Pass  \n",
       "2     7 Crore+     22 Lac+       KARNATAKA  Post Graduate  \n",
       "3     9 Crore+     24 Lac+           BIHAR  Post Graduate  \n",
       "4     2 Crore+     61 Lac+     WEST BENGAL       8th Pass  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareData(data):\n",
    "    data=data.drop(columns=['ID','Candidate','Constituency ∇'])\n",
    "    data.iloc[:,[2,3]]=(data.iloc[:,[2,3]]).apply(lambda x: x.str.replace(' Crore+','00000'))\n",
    "    data.iloc[:,[2,3]]=(data.iloc[:,[2,3]]).apply(lambda x: x.str.replace(' Lac+','000'))\n",
    "    data.iloc[:,[2,3]]=(data.iloc[:,[2,3]]).apply(lambda x: x.str.replace(' Thou+','0'))\n",
    "    data.iloc[:,[2,3]]=(data.iloc[:,[2,3]]).apply(lambda x: x.str.replace(' Hund+',''))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train and y_train are your training features and labels\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "accuracy_scorer=make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transform(data,eduEncoder,type='train'):\n",
    "\n",
    "    scaler=StandardScaler()\n",
    "    minmax=MinMaxScaler()\n",
    "    encoder=OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    # data=data.drop(columns=['Party'])\n",
    "    # data[['Criminal Case']]=scaler.fit_transform(data[['Criminal Case']])\n",
    "    # data['Party']=encoders[0].transform(data['Party'])\n",
    "    # data['state']=encoders[1].transform(data['state'])\n",
    "# Fit and transform the encoder\n",
    "    encoded_features = encoder.fit_transform(data[['Party', 'state']])\n",
    "\n",
    "    # Get the feature names from the encoder\n",
    "    feature_names = encoder.get_feature_names_out(['Party', 'state'])\n",
    "\n",
    "\n",
    "    # Create a DataFrame from the transformed data with the correct column names\n",
    "    encoded_data = pd.DataFrame(encoded_features, columns=feature_names)\n",
    "\n",
    "    data=data.drop(columns=['Party','state'])\n",
    "\n",
    "\n",
    "\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    data = pd.concat([data, encoded_data], axis=1)\n",
    "\n",
    "    data = data.astype({'Total Assets': float, 'Liabilities':float})\n",
    "\n",
    "\n",
    "\n",
    "    data[\"Criminal Case\"] = (data[\"Criminal Case\"] > 0).astype(int) # binary variable\n",
    "    data[\"Assets_liability\"] =  (data['Total Assets']>data['Liabilities']).astype(int)# asset to liability ratio prop to education\n",
    "\n",
    "    # data[['Total Assets', 'Liabilities']] = scaler.fit_transform(data[['Total Assets', 'Liabilities']])\n",
    "\n",
    "    if(type=='test'):\n",
    "        data=data.drop(columns=['Liabilities'])\n",
    "        return data\n",
    "    # data['Education']=encoders[2].transform(data['Education'])\n",
    "\n",
    "    data['Education']=data['Education'].map(eduEncoder)\n",
    "    y=data['Education']\n",
    "    X=data.drop(columns=['Education','Liabilities']) \n",
    "\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubmission(education_mapping,model,X_test):\n",
    "    y_test=model.predict(X_test)\n",
    "    df = pd.read_csv('test.csv')\n",
    "    df = df[['ID']]\n",
    "    # df['Education']=encoderEducation.classes_[y_test]\n",
    "    # df['Education'] = [list(education_mapping.keys())[9] if i > 8 else list(education_mapping.keys())[i] for i in y_test]\n",
    "    df['Education'] = [list(education_mapping.keys())[i] for i in y_test]\n",
    "\n",
    "    # Save the DataFrame to a new CSV file\n",
    "    df.to_csv('output.csv', index=False)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getF1Score(model,X_val,y_val):\n",
    "    y_pred = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred,average='weighted')\n",
    "    print(\"F1 Score:\", f1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimiseModel(model,X,y,param_grid):\n",
    "\n",
    "    # Initialize GridSearchCV with F1 score as the scoring metric\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=f1_scorer, n_jobs=-1)\n",
    "    # grid_search = RandomizedSearchCV(estimator = model, param_distributions = param_grid, cv = 5, scoring=f1_scorer, n_jobs = -1)\n",
    "    # Perform grid search to find the best parameters\n",
    "    grid_search.fit(X ,y)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best F1 Score:\", best_score)\n",
    "    return best_params\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=PrepareData(test)\n",
    "train_data=PrepareData(train)\n",
    "# train_data_0= (train_data[train_data['Total Assets'] != '0']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=pd.read_csv(\"test.csv\")\n",
    "# train=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train=PrepareData(train)\n",
    "# test=PrepareData(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['Party'] = train['Party'].astype('category').cat.codes\n",
    "# train['Education'] = train['Education'].astype('category').cat.codes\n",
    "# train['state'] = train['state'].astype('category').cat.codes\n",
    "\n",
    "# train = train.astype({'Party': int, 'Total Assets': float, 'Liabilities':float,'state':int,'Education':int})\n",
    "# train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from scipy.stats import chi2_contingency\n",
    "\n",
    "# # Assume 'data' is your DataFrame with 'Party' and 'Education level' columns\n",
    "\n",
    "# # Create a contingency table (cross-tabulation)\n",
    "# contingency_table = pd.crosstab(train['Criminal Case'], train['Education'])\n",
    "\n",
    "\n",
    "# # Perform the chi-squared test\n",
    "# chi2_stat, p_val, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Chi-squared statistic:\", chi2_stat)\n",
    "# print(\"p-value:\", p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoderParty=LabelEncoder()\n",
    "encoderState=LabelEncoder()\n",
    "encoderEducation=LabelEncoder()\n",
    "encoderParty.fit(train['Party'])\n",
    "encoderState.fit(train['state'])\n",
    "encoderEducation.fit(train['Education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=Transform(train_data,education_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def oversample(X,y,sampling_strategy):\n",
    "    # sampling_strategy = {\n",
    "    #     5: 531,   # Keep the majority class unchanged\n",
    "    #     6: 450, # 432/531\n",
    "    #     4: 450, # 349/531\n",
    "    #     7: 450, # 339/531\n",
    "    #     3: 300, # 227/531\n",
    "    #     2: 100, # 78/531\n",
    "    #     8: 100, # 52/531\n",
    "    #     9: 100, # 28/531\n",
    "    #     0: 100, # 14/531\n",
    "    #     1: 100, # 9/531\n",
    "    # }\n",
    "\n",
    "    smote = SMOTE(random_state=69,sampling_strategy=sampling_strategy)\n",
    "\n",
    "    # Apply SMOTE to generate synthetic samples\n",
    "    X_resampled, y_resampled = smote.fit_resample(X,y)\n",
    "\n",
    "    return X_resampled,y_resampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=Transform(test_data,np.array((encoderParty,encoderState,encoderEducation)),'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.15,random_state=69,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train0,X_val0,y_train0,y_val0=train_test_split(X0,y0,test_size=0.15,random_state=69,stratify=y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education\n",
       "5    411\n",
       "6    336\n",
       "4    264\n",
       "7    260\n",
       "3    176\n",
       "2     64\n",
       "8     41\n",
       "9     20\n",
       "0     10\n",
       "1      7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling_strategy = {\n",
    "#     5: 451,   # Keep the majority class unchanged\n",
    "#     6: 367, # 432/531\n",
    "#     4: 297, # 349/531\n",
    "#     7: 288, # 339/531\n",
    "#     3: 250, # 227/531\n",
    "#     2: 150, # 78/531\n",
    "#     8: 125, # 52/531\n",
    "#     9: 70, # 28/531\n",
    "#     0: 50, # 14/531\n",
    "#     1: 50, # 9/531\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_strategy= {\n",
    "    5: 451,   # Keep the majority class unchanged\n",
    "    6: 367, # 432/531\n",
    "    4: 297, # 349/531\n",
    "    7: 288, # 339/531\n",
    "    3: 250, # 227/531\n",
    "    2: 150, # 78/531\n",
    "    8: 125, # 52/531\n",
    "    9: 75, # 28/531\n",
    "    0: 50, # 14/531\n",
    "    1: 50, # 9/531\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled,y_resampled=oversample(X_train,y_train,sampling_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the classifier on the testing data\n",
    "# accuracy = classifier.score(X_val, y_val)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heirarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heirarchialModel(heirarchy,X,y):\n",
    "\n",
    "    broad_trained_models = {}\n",
    "    y1=y.copy()\n",
    "\n",
    "    # Dictionary to store trained models for predicting finer classes within each broad class\n",
    "    finer_trained_models = {}\n",
    "    # Train classification models for broad classes\n",
    "    for broad_level, broad_classes in heirarchy.items():\n",
    "        broad_subset_indices = y.isin(broad_classes)\n",
    "        y1[broad_subset_indices]=broad_level\n",
    "        # print(broad_classes,broad_subset_indices)\n",
    "        X_train_broad = X[broad_subset_indices]\n",
    "        y_train_broad = y[broad_subset_indices]\n",
    "        # X_train, X_test, y_train, y_test = train_test_split(broad_subset_X, broad_subset_y, test_size=0.2, random_state=69, stratify=broad_subset_y)\n",
    "        # clf = RandomForestClassifier(random_state=69)\n",
    "        clf=optimiseRandomForest(X_train_broad,y_train_broad)\n",
    "        clf.fit(X_train_broad, y_train_broad)\n",
    "        broad_trained_models[broad_level] = clf\n",
    "\n",
    "    BroadModel = optimiseGboost(X,y1)\n",
    "    BroadModel.fit(X, y1)\n",
    "    return BroadModel,broad_trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_classification(X_val,y_val,BroadModel,broad_trained_models):\n",
    "    y_predict1=BroadModel.predict(X_val)\n",
    "    y_predict=np.zeros((len(y_predict1)))\n",
    "    for i in range(0,len(y_predict1)):\n",
    "        y_predict[i]=broad_trained_models[y_predict1[i]].predict(X_val.iloc[[i]])[0]\n",
    "    f1 = f1_score(y_val, y_predict,average='weighted')\n",
    "    print(\"F1 Score:\", f1)  \n",
    "    return y_predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_leaf_nodes': 200, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best F1 Score: 0.6104903848505451\n",
      "Best Parameters: {'max_leaf_nodes': 200, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best F1 Score: 1.0\n",
      "Best Parameters: {'max_leaf_nodes': 200, 'min_samples_split': 7, 'n_estimators': 100}\n",
      "Best F1 Score: 0.36353310554575946\n",
      "Best Parameters: {'max_leaf_nodes': 200, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best F1 Score: 0.6814814814814814\n",
      "Best Parameters: {'learning_rate': 0.2, 'max_leaf_nodes': 50, 'n_estimators': 125}\n",
      "Best F1 Score: 0.5450662783797233\n",
      "F1 Score: 0.24855027596702642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4., 6., 6., 5., 9., 5., 7., 7., 6., 5., 5., 5., 5., 6., 5., 7., 5.,\n",
       "       5., 5., 5., 6., 5., 4., 5., 5., 5., 5., 5., 7., 7., 5., 6., 5., 5.,\n",
       "       4., 6., 6., 5., 5., 5., 5., 5., 6., 5., 5., 5., 5., 4., 5., 7., 7.,\n",
       "       7., 5., 7., 5., 6., 5., 5., 5., 5., 5., 6., 7., 5., 7., 3., 2., 5.,\n",
       "       8., 7., 6., 5., 5., 6., 5., 6., 5., 6., 7., 7., 7., 5., 6., 6., 4.,\n",
       "       5., 3., 5., 7., 5., 6., 5., 5., 5., 6., 6., 6., 7., 6., 5., 5., 5.,\n",
       "       6., 6., 6., 6., 4., 5., 3., 7., 6., 7., 7., 7., 5., 4., 5., 7., 7.,\n",
       "       5., 6., 6., 5., 5., 5., 5., 5., 5., 6., 7., 7., 5., 5., 3., 5., 6.,\n",
       "       5., 4., 7., 6., 6., 6., 6., 5., 6., 6., 6., 5., 5., 5., 5., 7., 5.,\n",
       "       5., 6., 3., 7., 6., 5., 5., 3., 7., 6., 4., 5., 6., 6., 5., 6., 5.,\n",
       "       5., 7., 5., 6., 5., 3., 4., 6., 5., 5., 9., 6., 7., 7., 3., 7., 5.,\n",
       "       5., 5., 7., 5., 5., 5., 6., 6., 5., 5., 5., 6., 5., 6., 6., 6., 5.,\n",
       "       5., 7., 5., 2., 5., 5., 5., 6., 6., 7., 7., 4., 5., 6., 5., 5., 5.,\n",
       "       6., 5., 4., 6., 6., 5., 5., 7., 4., 5., 5., 6., 5., 6., 5., 5., 4.,\n",
       "       3., 5., 4., 5., 7., 7., 3., 4., 5., 7., 7., 5., 7., 6., 5., 5., 5.,\n",
       "       7., 7., 5., 6., 5., 7., 6., 7., 5., 6., 6., 6., 3., 5., 7., 3., 4.,\n",
       "       6., 4., 2., 6., 6., 6., 5., 6., 5.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heirarchy = {\n",
    "    0: [1, 2, 3],\n",
    "    1: [4],\n",
    "    2: [5, 6, 7, 8],\n",
    "    3: [0, 9]\n",
    "}\n",
    "BroadModel,broad_trained_models=heirarchialModel(heirarchy,X_train,y_train)\n",
    "hierarchical_classification(X_val,y_val,BroadModel,broad_trained_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.005805515239477504\n"
     ]
    }
   ],
   "source": [
    "y_t=np.ones(len(X_test))\n",
    "y_test=hierarchical_classification(X_test,y_t,BroadModel,broad_trained_models)\n",
    "y_test=y_test.astype(int)\n",
    "df = pd.read_csv('test.csv')\n",
    "df = df[['ID']]\n",
    "df['Education'] = [list(education_mapping.keys())[i] for i in y_test]\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Cross-Validation Scores, A: 0.1843111575396864  B:  0.28769769833981995\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dt_classifier=DecisionTreeClassifier(random_state=1)\n",
    "dt_scoresA = cross_val_score(dt_classifier, X_train, y_train, cv=5,scoring=f1_scorer)\n",
    "dt_scoresF = cross_val_score(dt_classifier, X_resampled, y_resampled, cv=5,scoring=f1_scorer)\n",
    "print(\"Decision Tree Classifier Cross-Validation Scores, A:\", dt_scoresA.mean(),\" B: \",dt_scoresF.mean() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimiseDecisionTree(X,y):\n",
    "    # Define the parameter grid to search\n",
    "    param_grid = {\n",
    "        # 'criterion': ['gini', 'entropy'],\n",
    "        # 'max_depth': [1, 2, 5, 10, 15],\n",
    "        'min_samples_split': [2, 3, 5, 10],\n",
    "        'min_samples_leaf': [1, 2,5, 10, 15],\n",
    "        # 'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_leaf_nodes':[200, 500,700,1000,1500,2000]\n",
    "    }\n",
    "    dt_classifier=DecisionTreeClassifier(random_state=1)\n",
    "    best_params=optimiseModel(dt_classifier,X,y,param_grid)\n",
    "    # Initialize GridSearchCV with F1 score as the scoring metric\n",
    "    best_dt_classifier = DecisionTreeClassifier(random_state=1,**best_params)\n",
    "    return best_dt_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_leaf_nodes': 700, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
      "Best F1 Score: 0.29194282701190144\n",
      "F1 Score: 0.21521457013729772\n"
     ]
    }
   ],
   "source": [
    "best_dt_classifier=optimiseDecisionTree(X_resampled,y_resampled)\n",
    "best_dt_classifier.fit(X_resampled, y_resampled)\n",
    "getF1Score(best_dt_classifier,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=createSubmission(education_mapping,best_dt_classifier,X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dt_classifier.fit(X, y)\n",
    "full=createSubmission(education_mapping,best_dt_classifier,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Cross-Validation Scores, A: 0.19853642971406887  B:  0.30156578444707716\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=69,oob_score=True)\n",
    "rf_scoresA = cross_val_score(rf_classifier, X_train, y_train, cv=5,scoring=f1_scorer)\n",
    "rf_scoresF = cross_val_score(rf_classifier, X_resampled, y_resampled, cv=5, scoring=f1_scorer)\n",
    "print(\"Random Forest Classifier Cross-Validation Scores, A:\", rf_scoresA.mean(),\" B: \" ,rf_scoresF.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_resampled=X_resampled.drop(columns=['Total Assets'])\n",
    "# X_val=X_val.drop(columns=['Total Assets'])\n",
    "# X_train=X_train.drop(columns=['Total Assets'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimiseRandomForest(X,y) :\n",
    "  # Define the parameter grid to search\n",
    "  # param_grid = {\n",
    "  #     'n_estimators': [100,500,1000],\n",
    "  #     # 'criterion': ['gini', 'entropy'],\n",
    "  #     # 'max_depth': [None, 10, 20],\n",
    "  #     'min_samples_split': [5,7,9,11],\n",
    "  #     # 'min_samples_leaf': [1, 2, 5,7,9],\n",
    "  #     'max_leaf_nodes':[200,500,1000,2000]\n",
    "  # }\n",
    "\n",
    "  #     # 'max_features': ['auto', 'sqrt', 'log2']\n",
    "  # # }\n",
    "  param_grid = {\n",
    "  'n_estimators': [50, 100, 150,200],\n",
    "#   Consider both Gini impurity and entropy for split criterion\n",
    "  # 'max_depth': [2, 5, 10, 20, 100],  # Allow the tree to grow deeper or limit its depth\n",
    "  'min_samples_split': [2,5,7,9],  # Vary the minimum number of samples required to split an internal node\n",
    "  'max_leaf_nodes':[200,500,700,1000]\n",
    "  # 'min_samples_leaf': [1, 2, 5], \n",
    "  # 'min_impurity_decrease' : [0.001, 0.005, 0.0001] # Vary the minimum number of samples required to be a leaf node\n",
    "  # 'max_features': ['auto', 'sqrt', 'log2'],  # Consider different ways of selecting features for splitting\n",
    "  # 'max_leaf_nodes': [10, 100, 200, 500]  # Limit the maximum number of leaf nodes\n",
    "  }\n",
    "  # param_grid = {'n_estimators':[100,500,1000,1500],\n",
    "  #               'max_leaf_nodes':[200,500,1000],\n",
    "  #               'min_samples_split':[2,5,7,10,11]\n",
    "  #             #   'max_depth': [None,2,5,10]\n",
    "  #               }\n",
    "  rf_classifier=RandomForestClassifier(random_state=69)\n",
    "  best_params=optimiseModel(rf_classifier,X,y,param_grid)\n",
    "  best_rf_classifier = RandomForestClassifier(random_state=69,**best_params)\n",
    "  return best_rf_classifier\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Criminal Case</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Party_AAP</th>\n",
       "      <th>Party_AIADMK</th>\n",
       "      <th>Party_AITC</th>\n",
       "      <th>Party_BJD</th>\n",
       "      <th>Party_BJP</th>\n",
       "      <th>Party_CPI</th>\n",
       "      <th>Party_CPI(M)</th>\n",
       "      <th>Party_DMK</th>\n",
       "      <th>...</th>\n",
       "      <th>state_PUDUCHERRY</th>\n",
       "      <th>state_PUNJAB</th>\n",
       "      <th>state_RAJASTHAN</th>\n",
       "      <th>state_SIKKIM</th>\n",
       "      <th>state_TAMIL NADU</th>\n",
       "      <th>state_TRIPURA</th>\n",
       "      <th>state_UTTAR PRADESH</th>\n",
       "      <th>state_UTTARAKHAND</th>\n",
       "      <th>state_WEST BENGAL</th>\n",
       "      <th>Assets_liability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.000000e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.000000e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7.900000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.600000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.600000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>1</td>\n",
       "      <td>5.047093e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>0</td>\n",
       "      <td>4.229109e+05</td>\n",
       "      <td>0.229109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.770891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.770891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>0</td>\n",
       "      <td>2.001008e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>0</td>\n",
       "      <td>1.122629e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>0</td>\n",
       "      <td>1.386057e+06</td>\n",
       "      <td>0.113943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.886057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.886057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2103 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Criminal Case  Total Assets  Party_AAP  Party_AIADMK  Party_AITC  \\\n",
       "0                 0  9.000000e+05   0.000000           0.0         0.0   \n",
       "1                 1  3.000000e+06   0.000000           0.0         0.0   \n",
       "2                 1  7.900000e+04   0.000000           0.0         0.0   \n",
       "3                 0  3.600000e+04   0.000000           0.0         0.0   \n",
       "4                 1  5.600000e+04   0.000000           0.0         0.0   \n",
       "...             ...           ...        ...           ...         ...   \n",
       "2098              1  5.047093e+06   0.000000           0.0         0.0   \n",
       "2099              0  4.229109e+05   0.229109           0.0         0.0   \n",
       "2100              0  2.001008e+05   0.000000           0.0         0.0   \n",
       "2101              0  1.122629e+05   0.000000           0.0         0.0   \n",
       "2102              0  1.386057e+06   0.113943           0.0         0.0   \n",
       "\n",
       "      Party_BJD  Party_BJP  Party_CPI  Party_CPI(M)  Party_DMK  ...  \\\n",
       "0           0.0   1.000000        0.0           0.0        0.0  ...   \n",
       "1           1.0   0.000000        0.0           0.0        0.0  ...   \n",
       "2           0.0   1.000000        0.0           0.0        0.0  ...   \n",
       "3           0.0   0.000000        0.0           0.0        0.0  ...   \n",
       "4           0.0   1.000000        0.0           0.0        0.0  ...   \n",
       "...         ...        ...        ...           ...        ...  ...   \n",
       "2098        0.0   1.000000        0.0           0.0        0.0  ...   \n",
       "2099        0.0   0.770891        0.0           0.0        0.0  ...   \n",
       "2100        0.0   1.000000        0.0           0.0        0.0  ...   \n",
       "2101        0.0   1.000000        0.0           0.0        0.0  ...   \n",
       "2102        0.0   0.886057        0.0           0.0        0.0  ...   \n",
       "\n",
       "      state_PUDUCHERRY  state_PUNJAB  state_RAJASTHAN  state_SIKKIM  \\\n",
       "0                  0.0           0.0         0.000000           0.0   \n",
       "1                  0.0           0.0         0.000000           0.0   \n",
       "2                  0.0           0.0         0.000000           0.0   \n",
       "3                  0.0           0.0         1.000000           0.0   \n",
       "4                  0.0           0.0         0.000000           0.0   \n",
       "...                ...           ...              ...           ...   \n",
       "2098               0.0           0.0         0.066554           0.0   \n",
       "2099               0.0           0.0         0.000000           0.0   \n",
       "2100               0.0           0.0         0.000000           0.0   \n",
       "2101               0.0           0.0         0.000000           0.0   \n",
       "2102               0.0           0.0         0.886057           0.0   \n",
       "\n",
       "      state_TAMIL NADU  state_TRIPURA  state_UTTAR PRADESH  state_UTTARAKHAND  \\\n",
       "0                  0.0            0.0             0.000000                0.0   \n",
       "1                  0.0            0.0             0.000000                0.0   \n",
       "2                  0.0            0.0             0.000000                0.0   \n",
       "3                  0.0            0.0             0.000000                0.0   \n",
       "4                  0.0            0.0             0.000000                0.0   \n",
       "...                ...            ...                  ...                ...   \n",
       "2098               0.0            0.0             0.000000                0.0   \n",
       "2099               0.0            0.0             0.770891                0.0   \n",
       "2100               0.0            0.0             0.000000                0.0   \n",
       "2101               0.0            0.0             0.000000                0.0   \n",
       "2102               0.0            0.0             0.000000                0.0   \n",
       "\n",
       "      state_WEST BENGAL  Assets_liability  \n",
       "0                   0.0                 1  \n",
       "1                   0.0                 1  \n",
       "2                   1.0                 1  \n",
       "3                   0.0                 1  \n",
       "4                   0.0                 1  \n",
       "...                 ...               ...  \n",
       "2098                0.0                 1  \n",
       "2099                0.0                 1  \n",
       "2100                0.0                 1  \n",
       "2101                0.0                 1  \n",
       "2102                0.0                 1  \n",
       "\n",
       "[2103 rows x 54 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_leaf_nodes': 200, 'min_samples_split': 9, 'n_estimators': 50}\n",
      "Best F1 Score: 0.21507699906635178\n",
      "F1 Score: 0.2397469263993728\n"
     ]
    }
   ],
   "source": [
    "best_rf_classifier = optimiseRandomForest(X_train,y_train)\n",
    "best_rf_classifier.fit(X_train, y_train)\n",
    "getF1Score(best_rf_classifier,X_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, ..., 5, 8, 6])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_classifier.fit(X, y)\n",
    "createSubmission(education_mapping,best_rf_classifier,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Cross-Validation Scores, A: 0.10630797829234247  B:  0.07574034041877904\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Logistic Regression\n",
    "logistic_classifier = LogisticRegression(max_iter=10000)\n",
    "logistic_scoresA = cross_val_score(logistic_classifier, X_train, y_train, cv=5,scoring=f1_scorer)\n",
    "logistic_scoresF = cross_val_score(logistic_classifier, X_resampled, y_resampled, cv=5,scoring=f1_scorer)\n",
    "print(\"Logistic Regression Cross-Validation Scores, A:\", logistic_scoresA.mean(),\" B: \",logistic_scoresF.mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best F1 Score: 0.1970961141466027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.19417397        nan 0.10630798 0.10630798 0.19264482        nan\n",
      " 0.10630798 0.10630798 0.19629085        nan 0.10630798 0.10630798\n",
      " 0.19554803        nan 0.10630798 0.10630798 0.19619563        nan\n",
      " 0.10630798 0.10630798 0.19709611        nan 0.10630798 0.10630798]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'penalty': ['l1', \"l2\"],  # Regularization penalty\n",
    "    'C': [5, 10, 100, 500, 600, 1000], # Inverse of regularization strength,\n",
    "    \"solver\" : [\"liblinear\", \"lbfgs\"]\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV with F1 score as the scoring metric\n",
    "grid_search = GridSearchCV(estimator=logistic_classifier, param_grid=param_grid, cv=5, scoring=f1_scorer, n_jobs=-1)\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best F1 Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.20836271128558578\n"
     ]
    }
   ],
   "source": [
    "# grid_search.fit(X_resampled, y_resampled)\n",
    "getF1Score(grid_search,X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_scoresA = cross_val_score(svm_classifier, X_resampled, y_resampled, cv=5,scoring=accuracy_scorer)\n",
    "svm_scoresF = cross_val_score(svm_classifier, X_train, y_train, cv=5,scoring=f1_scorer)\n",
    "print(\"Support Vector Machine Cross-Validation Scores, A:\", svm_scoresA.mean(),\" B: \",svm_scoresF.mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimiseSVM(X,y):\n",
    "        \n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],  \n",
    "        'gamma': [1, 0.1, 0.01, 0.001], \n",
    "        'kernel': ['rbf', 'linear', 'poly']\n",
    "    }\n",
    "\n",
    "    # Initialize K-Nearest Neighbors Classifier\n",
    "    svm_classifier = SVC(random_state=42)\n",
    "    \n",
    "    # Initialize GridSearchCV with F1 score as the scoring metric\n",
    "    best_params=optimiseModel(svm_classifier,X,y,param_grid)\n",
    "    best_knn_classifier = SVC(random_state=42,**best_params)\n",
    "\n",
    "    return best_knn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Best F1 Score: 0.260113301034751\n",
      "F1 Score: 0.20781830473371787\n"
     ]
    }
   ],
   "source": [
    "best_svm_classifier = optimiseSVM(X_resampled,y_resampled)\n",
    "\n",
    "best_svm_classifier.fit(X_train, y_train)\n",
    "getF1Score(best_svm_classifier,X_val,y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K nearest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "def optimiseKNN(X,y):\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3,4, 5,6, 9,11,15],  # Number of neighbors\n",
    "        'weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
    "    }\n",
    "\n",
    "    # Initialize K-Nearest Neighbors Classifier\n",
    "    knn_classifier = KNeighborsClassifier()\n",
    "    \n",
    "    # Initialize GridSearchCV with F1 score as the scoring metric\n",
    "    best_params=optimiseModel(knn_classifier,X,y,param_grid)\n",
    "    best_knn_classifier = KNeighborsClassifier(**best_params)\n",
    "\n",
    "    return best_knn_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best F1 Score: 0.2643971878874038\n",
      "F1 Score: 0.21112173395193842\n"
     ]
    }
   ],
   "source": [
    "best_knn_classifier = optimiseKNN(X_resampled,y_resampled)\n",
    "\n",
    "best_knn_classifier.fit(X_resampled, y_resampled)\n",
    "getF1Score(best_knn_classifier,X_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 3, ..., 5, 8, 5])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn_classifier.fit(X_resampled, y_resampled)\n",
    "createSubmission(education_mapping,best_knn_classifier,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15658362989323843\n"
     ]
    }
   ],
   "source": [
    "nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "nca_pipe.fit(X_resampled, y_resampled)\n",
    "print(nca_pipe.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'knn__n_neighbors': 5, 'knn__p': 1, 'knn__weights': 'distance', 'nca__n_components': 4}\n",
      "Best F1 Score: 0.27982314295212357\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'nca__n_components': [2,3,4],  # Number of components for NCA\n",
    "    'knn__n_neighbors': [5,7,9,11,13,15,17],  # Number of neighbors for \n",
    "    'knn__p':[1,2],\n",
    "    'knn__weights': ['uniform','distance'],  # Weight function used in prediction for KNN\n",
    "}\n",
    "\n",
    "# Create pipeline\n",
    "nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "knn = KNeighborsClassifier()\n",
    "nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "\n",
    "# Initialize GridSearchCV with F1 score as the scoring metric\n",
    "grid_search = GridSearchCV(estimator=nca_pipe, param_grid=param_grid, cv=10, scoring=f1_scorer, n_jobs=-1)\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best F1 Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.23324965668572428\n"
     ]
    }
   ],
   "source": [
    "# Define parameters for NCA\n",
    "nca_params = {'n_components': 4, 'random_state': 42}\n",
    "\n",
    "# Define parameters for KNN\n",
    "knn_params = {'n_neighbors': 5, 'weights': 'distance','p':1}\n",
    "\n",
    "# Create the pipeline with parameters\n",
    "nca_pipe = Pipeline([\n",
    "    ('nca', NeighborhoodComponentsAnalysis(**nca_params)),\n",
    "    ('knn', KNeighborsClassifier(**knn_params))\n",
    "])\n",
    "best_knn_classifier = nca_pipe\n",
    "best_knn_classifier.fit(X_train, y_train)\n",
    "getF1Score(best_knn_classifier,X_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 4, ..., 8, 8, 5])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn_classifier.fit(X, y)\n",
    "createSubmission(education_mapping,best_knn_classifier,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Cross-Validation Scores, A: 0.1983389228030476  B:  0.2958181113973013\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=69)\n",
    "gb_scoresA = cross_val_score(gb_classifier, X_train, y_train, cv=5,scoring=f1_scorer)\n",
    "gb_scoresF = cross_val_score(gb_classifier, X_resampled, y_resampled, cv=5,scoring=f1_scorer)\n",
    "print(\"Gradient Boosting Classifier Cross-Validation Scores, A:\", gb_scoresA.mean(),\" B: \",gb_scoresF.mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimiseGboost(X,y):\n",
    "# Define the parameter grid to search\n",
    "    param_grid = {\n",
    "        'n_estimators': [100,125, 150,200],\n",
    "        # 'learning_rate': [0.005, 0.01, 0.1, 0.15, 0.2, 0.3],\n",
    "        'learning_rate':[0.2],\n",
    "        # 'max_depth': [1, 2,3, 5, 10, 20],\n",
    "        # 'min_samples_split': [2,5,7, 10,15],\n",
    "        # 'min_samples_leaf': [2, 5, 10, 50],\n",
    "        'max_leaf_nodes':[50,100,200,500]\n",
    "    }\n",
    "   # Initialize K-Nearest Neighbors Classifier\n",
    "    gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "    \n",
    "    # Initialize GridSearchCV with F1 score as the scoring metric\n",
    "    best_params=optimiseModel(gb_classifier,X,y,param_grid)\n",
    "    best_gb_classifier = GradientBoostingClassifier(random_state=42,**best_params)\n",
    "\n",
    "    return best_gb_classifier\n",
    "\n",
    "# Initialize GridSearchCV with F1 score as the scoring metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_resampled1=X_resampled[X_resampled['Total Assets']==0]\n",
    "# y_resampled1=y_resampled[X_resampled['Total Assets']==0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_resampled1=X_resampled1.drop(columns=['Total Assets'])\n",
    "# X_val=X_val.drop(columns=['Total Assets'])\n",
    "# # y_resampled1=X_resampled1.drop(columns=['Total Assets'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.2, 'max_leaf_nodes': 50, 'n_estimators': 125}\n",
      "Best F1 Score: 0.19989223166602008\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.2, max_leaf_nodes=50,\n",
       "                           n_estimators=125, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.2, max_leaf_nodes=50,\n",
       "                           n_estimators=125, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.2, max_leaf_nodes=50,\n",
       "                           n_estimators=125, random_state=42)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gb_classifier = optimiseGboost(X_train,y_train)\n",
    "best_gb_classifier.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.23156182439498044\n"
     ]
    }
   ],
   "source": [
    "getF1Score(best_gb_classifier,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 7, ..., 5, 8, 6])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gb_classifier.fit(X, y)\n",
    "createSubmission(education_mapping,best_gb_classifier,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'penalty': 'elasticnet'}\n",
      "Best F1 Score: 0.04758914439640461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "360 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "360 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 905, in fit\n",
      "    self._more_validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py\", line 153, in _more_validate_params\n",
      "    raise ValueError(\"eta0 must be > 0\")\n",
      "ValueError: eta0 must be > 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.02916743 0.032749   0.04222423 0.0328276  0.032749   0.032749\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.03254649 0.02413421 0.03209252 0.03711973 0.02245863 0.03729878\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.02398435 0.02413421 0.04758914 0.0454263  0.02245863 0.03840978\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.01810277 0.02413421 0.0227285  0.02961913 0.02245863 0.0233313\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sgd_classifier=SGDClassifier(random_state=69)\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'loss': ['hinge', 'modified_huber'],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV with F1 score as the scoring metric\n",
    "grid_search = GridSearchCV(estimator=sgd_classifier, param_grid=param_grid, cv=5, scoring=f1_scorer)\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best F1 Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.10714357520558136\n"
     ]
    }
   ],
   "source": [
    "best_sgd_classifier = SGDClassifier(random_state=2,**best_params)\n",
    "best_sgd_classifier.fit(X_train, y_train)\n",
    "getF1Score(best_sgd_classifier,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
